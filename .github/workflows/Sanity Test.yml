name: Model Evaluation and Sanity Test

on:
  pull_request:
    branches: [main]

permissions:
  contents: write
  pull-requests: write

env:
  GCP_PROJECT_ID: premium-cipher-462011-p3
  ARTIFACT_REGISTRY: us-central1-docker.pkg.dev
  MODEL_BUCKET_URI: gs://mlops-course-premium-cipher-462011-p3-unique/my-models/iris-classifier-week-1/model.joblib


jobs:
  test_model:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - uses: iterative/setup-cml@v2

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create GCP credentials file
        run: |
          echo "Setting up GCP credentials..."
          echo '${{ secrets.GCP_SA_KEY }}' > gcp-key.json
          echo "Credentials written to gcp-key.json"

      - name: Authenticate with Google Cloud
        run: |
          gcloud auth activate-service-account --key-file=gcp-key.json
          echo "Authenticated with GCP"

          export GOOGLE_APPLICATION_CREDENTIALS=$(pwd)/gcp-key.json
          
          echo "Configuring DVC to use gcloud credentials..."
          dvc remote add -d gcsremote $MODEL_BUCKET_URI
          dvc remote modify gcsremote credentialpath $(pwd)/gcp-key.json

          echo "Running DVC pull:"
          dvc pull -v

      - name: Data Quality Check
        id: label_check
        run: |
          echo "## Data Quality Report" >> report.md
          python src/check_labels.py --data-path data/iris.csv >> report.md
          
          SUSPICIOUS_COUNT=$(grep "Found" report.md | awk '{print $2}')
          echo "Suspicious labels found: $SUSPICIOUS_COUNT"
          echo "count=$SUSPICIOUS_COUNT" >> "$GITHUB_OUTPUT"

      - name: Validate Label Quality
        run: |
          echo "Checking if suspicious count is within tolerance..."
          if [ ${{ steps.label_check.outputs.count }} -gt 10 ]; then
            echo "Error: High number of suspicious labels detected (${{ steps.label_check.outputs.count }}). Aborting workflow."
            exit 1
          else
            echo "Data quality check passed. Proceeding with training."
          fi

      - name: Run Training and Core Evaluation
        run: |
          python src/train.py
          python src/evaluate.py
      
      - name: Run Tests
        run: |
          echo "## Test Results" >> report.md
          pytest --tb=short --disable-warnings >> report.md 2>&1 || echo "Tests failed" >> report.md
          echo "Tests completed on $(date)" >> report.md

      ### --- NEW RESPONSIBLE AI STAGE --- ###
      - name: Run Responsible AI Checks
        run: |
          echo "## Responsible AI Reports" >> report.md
          
          echo "### 1. Generating SHAP Explanations..." >> report.md
          python src/generate_explanations.py >> report.md
          
          echo "### 2. Checking Fairness (Fairlearn)..." >> report.md
          python src/check_fairness.py >> report.md

          echo "### 3. Checking Data Drift (Evidently)..." >> report.md
          python src/check_drift.py >> report.md

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: model-artifacts
          path: |
            artifacts/
            report.md

      - name: Setup CML
        uses: iterative/setup-cml@v2
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Comment on PR with CML
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          source .venv/bin/activate
          # Append the SHAP plot to the report for CML
          echo "## Model Explainability (SHAP)" >> report.md
          echo "![SHAP Summary](./artifacts/shap_summary_global.png)" >> report.md
          
          cml comment create report.md
